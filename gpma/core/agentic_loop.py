"""
Agentic Loop Module - ReAct (Reasoning + Acting) Implementation

This module implements the core agentic loop that transforms GPMA from a
task-execution framework into a true autonomous agent system.

THE REACT PATTERN:
The ReAct (Reasoning and Acting) pattern interleaves reasoning and action:
1. OBSERVE - Gather information about current state
2. THINK - Reason about what to do next (using LLM)
3. ACT - Execute the chosen action
4. OBSERVE - See the results
5. REFLECT - Evaluate and decide: continue, retry, or complete

This creates an autonomous loop where the agent pursues goals intelligently,
not just executes predetermined steps.

KEY DIFFERENCES FROM WORKFLOW ORCHESTRATION:
- Workflow: Task A → Task B → Task C (fixed sequence)
- Agentic: Goal → Think → Act → Observe → Think → ... (dynamic)

USAGE:
    from gpma.core.agentic_loop import AgenticLoop, AgenticContext
    from gpma.llm.providers import OllamaProvider

    provider = OllamaProvider(model="llama3.1")
    loop = AgenticLoop(llm_provider=provider)

    result = await loop.run(
        goal="Research Python async patterns and summarize the key concepts",
        tools=[web_search_tool, summarize_tool],
        max_iterations=10
    )
"""

from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional, Union
from enum import Enum, auto
from datetime import datetime
import asyncio
import json
import logging
import uuid

logger = logging.getLogger(__name__)


class LoopStatus(Enum):
    """Status of the agentic loop."""
    RUNNING = auto()
    COMPLETED = auto()
    FAILED = auto()
    MAX_ITERATIONS = auto()
    STOPPED = auto()


class ActionType(Enum):
    """Types of actions the agent can take."""
    USE_TOOL = "use_tool"
    RESPOND = "respond"
    ASK_USER = "ask_user"
    DELEGATE = "delegate"
    WAIT = "wait"
    COMPLETE = "complete"


@dataclass
class Observation:
    """
    Represents what the agent observes/perceives.

    Observations come from:
    - Tool execution results
    - Environment state
    - User input
    - Other agents' messages
    """
    source: str  # Where this observation came from
    content: Any  # The actual observation data
    timestamp: datetime = field(default_factory=datetime.now)
    observation_type: str = "result"  # result, error, input, state
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_prompt_string(self) -> str:
        """Format observation for LLM prompt."""
        if isinstance(self.content, dict):
            content_str = json.dumps(self.content, indent=2, default=str)
        else:
            content_str = str(self.content)

        return f"[{self.observation_type.upper()}] from {self.source}:\n{content_str}"


@dataclass
class Thought:
    """
    Represents the agent's reasoning/thinking.

    Thoughts are generated by the LLM and include:
    - Analysis of current state
    - Reasoning about what to do
    - Planned next action
    """
    reasoning: str  # The agent's chain of thought
    next_action: ActionType  # What to do next
    action_input: Dict[str, Any] = field(default_factory=dict)  # Parameters for action
    confidence: float = 0.0  # How confident (0-1)
    alternatives_considered: List[str] = field(default_factory=list)
    goal_progress: float = 0.0  # Estimated progress toward goal (0-1)
    should_continue: bool = True  # Whether to continue the loop

    def to_dict(self) -> Dict[str, Any]:
        return {
            "reasoning": self.reasoning,
            "next_action": self.next_action.value,
            "action_input": self.action_input,
            "confidence": self.confidence,
            "alternatives_considered": self.alternatives_considered,
            "goal_progress": self.goal_progress,
            "should_continue": self.should_continue
        }


@dataclass
class Action:
    """
    Represents an action the agent takes.
    """
    action_type: ActionType
    tool_name: Optional[str] = None
    parameters: Dict[str, Any] = field(default_factory=dict)
    result: Any = None
    success: bool = False
    error: Optional[str] = None
    execution_time: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "action_type": self.action_type.value,
            "tool_name": self.tool_name,
            "parameters": self.parameters,
            "success": self.success,
            "error": self.error,
            "execution_time": self.execution_time
        }


@dataclass
class Reflection:
    """
    Agent's reflection on an action's outcome.

    Reflection enables self-correction by evaluating:
    - Did the action succeed?
    - Did it move toward the goal?
    - What should be done differently?
    """
    action_succeeded: bool
    goal_progress_made: bool
    lesson_learned: str
    should_retry: bool = False
    retry_strategy: Optional[str] = None
    adjusted_approach: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "action_succeeded": self.action_succeeded,
            "goal_progress_made": self.goal_progress_made,
            "lesson_learned": self.lesson_learned,
            "should_retry": self.should_retry,
            "retry_strategy": self.retry_strategy,
            "adjusted_approach": self.adjusted_approach
        }


@dataclass
class Step:
    """A single step in the agentic loop."""
    step_number: int
    thought: Thought
    action: Action
    observation: Observation
    reflection: Optional[Reflection] = None
    timestamp: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "step_number": self.step_number,
            "thought": self.thought.to_dict(),
            "action": self.action.to_dict(),
            "observation": self.observation.to_prompt_string(),
            "reflection": self.reflection.to_dict() if self.reflection else None,
            "timestamp": self.timestamp.isoformat()
        }


@dataclass
class AgenticContext:
    """
    Context maintained throughout the agentic loop.

    This holds the state that persists across iterations.
    """
    goal: str
    original_goal: str
    observations: List[Observation] = field(default_factory=list)
    steps: List[Step] = field(default_factory=list)
    artifacts: Dict[str, Any] = field(default_factory=dict)  # Produced outputs
    variables: Dict[str, Any] = field(default_factory=dict)  # Working memory
    start_time: datetime = field(default_factory=datetime.now)

    def add_observation(self, observation: Observation):
        self.observations.append(observation)

    def add_step(self, step: Step):
        self.steps.append(step)

    def set_artifact(self, key: str, value: Any):
        self.artifacts[key] = value

    def get_recent_observations(self, n: int = 5) -> List[Observation]:
        return self.observations[-n:]

    def get_recent_steps(self, n: int = 3) -> List[Step]:
        return self.steps[-n:]

    def to_prompt_context(self) -> str:
        """Generate context string for LLM prompts."""
        parts = [f"GOAL: {self.goal}\n"]

        if self.steps:
            parts.append("RECENT HISTORY:")
            for step in self.get_recent_steps():
                parts.append(f"  Step {step.step_number}:")
                parts.append(f"    Thought: {step.thought.reasoning[:200]}...")
                parts.append(f"    Action: {step.action.action_type.value}")
                if step.action.tool_name:
                    parts.append(f"    Tool: {step.action.tool_name}")
                parts.append(f"    Result: {'Success' if step.action.success else 'Failed'}")

        if self.artifacts:
            parts.append(f"\nARTIFACTS PRODUCED: {list(self.artifacts.keys())}")

        return "\n".join(parts)


@dataclass
class AgenticTool:
    """
    A tool available to the agentic loop.

    Tools must be well-described so the LLM can decide when to use them.
    """
    name: str
    description: str
    parameters: Dict[str, Dict[str, str]]  # param_name -> {type, description, required}
    function: Callable

    def to_schema(self) -> Dict[str, Any]:
        """Convert to OpenAI-style function schema."""
        properties = {}
        required = []

        for param_name, param_info in self.parameters.items():
            properties[param_name] = {
                "type": param_info.get("type", "string"),
                "description": param_info.get("description", "")
            }
            if param_info.get("required", False):
                required.append(param_name)

        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": {
                    "type": "object",
                    "properties": properties,
                    "required": required
                }
            }
        }

    async def execute(self, **kwargs) -> Any:
        """Execute the tool."""
        if asyncio.iscoroutinefunction(self.function):
            return await self.function(**kwargs)
        return self.function(**kwargs)


@dataclass
class LoopResult:
    """Final result of the agentic loop."""
    status: LoopStatus
    goal: str
    achieved: bool
    final_answer: Any
    artifacts: Dict[str, Any]
    steps_taken: int
    total_time: float
    reasoning_trace: List[Dict[str, Any]]
    error: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "status": self.status.name,
            "goal": self.goal,
            "achieved": self.achieved,
            "final_answer": self.final_answer,
            "artifacts": self.artifacts,
            "steps_taken": self.steps_taken,
            "total_time": self.total_time,
            "error": self.error
        }


class AgenticLoop:
    """
    The core ReAct (Reasoning + Acting) loop implementation.

    This is the heart of the agentic system. It implements an autonomous
    loop where an LLM-powered agent reasons about goals and takes actions
    to achieve them.

    THE LOOP:
    ```
    while not goal_achieved and iterations < max:
        observation = observe()           # What do I see?
        thought = think(observation)      # What should I do?
        action = act(thought)             # Do it
        observation = observe(action)     # What happened?
        reflection = reflect(action)      # Did it work? What did I learn?

        if reflection.should_retry:
            adjust_approach()
    ```

    USAGE:
        loop = AgenticLoop(llm_provider)

        result = await loop.run(
            goal="Find and summarize recent AI news",
            tools=[search_tool, summarize_tool],
            max_iterations=10
        )

        print(result.final_answer)
        print(f"Achieved: {result.achieved}")
        print(f"Steps: {result.steps_taken}")
    """

    def __init__(
        self,
        llm_provider,
        system_prompt: Optional[str] = None,
        enable_reflection: bool = True,
        verbose: bool = False
    ):
        """
        Initialize the agentic loop.

        Args:
            llm_provider: LLM provider for reasoning
            system_prompt: Custom system prompt for the agent
            enable_reflection: Whether to reflect after each action
            verbose: Log detailed progress
        """
        self.llm = llm_provider
        self.enable_reflection = enable_reflection
        self.verbose = verbose

        self.system_prompt = system_prompt or self._default_system_prompt()

        # State
        self._running = False
        self._stop_requested = False

    def _default_system_prompt(self) -> str:
        return """You are an autonomous AI agent that reasons step-by-step to achieve goals.

For each step, you must:
1. ANALYZE the current situation and goal progress
2. DECIDE on the best next action
3. EXPLAIN your reasoning clearly

You have access to tools. Use them strategically to gather information and take actions.

RESPONSE FORMAT:
You must respond with a JSON object containing:
{
    "reasoning": "Your step-by-step thinking about what to do and why",
    "next_action": "use_tool" | "complete",
    "action_input": {
        "tool_name": "name of tool to use (if next_action is use_tool)",
        "parameters": {"param1": "value1"} (if using tool),
        "final_answer": "your complete final answer with all information gathered (if next_action is complete)"
    },
    "confidence": 0.0-1.0,
    "goal_progress": 0.0-1.0
}

CRITICAL RULES:
- Use "use_tool" when you need to gather more information or perform calculations
- Use "complete" ONLY when you have completed ALL parts of the goal
- NEVER use "respond" - always use "complete" when ready to give your final answer
- Break complex goals into smaller steps - use tools for EACH part
- If the goal has multiple parts (e.g., "find X AND calculate Y"), you MUST complete ALL parts before using "complete"
- When using "complete", provide a comprehensive final_answer that addresses EVERY part of the goal
- The final_answer MUST include the actual results from your tool calls (not just "goal achieved")

TERMINATION GUIDANCE:
- After 3-4 tool uses, you likely have enough information - consider completing
- Do NOT keep searching/analyzing indefinitely - synthesize what you have
- If you've used search, analyze, and summarize tools, you're ready to complete
- Avoid repetitive tool calls - if you've already searched for something, don't search again
- When goal_progress reaches 0.7 or higher, strongly consider completing
- A good answer with available information is better than endless searching
"""

    async def run(
        self,
        goal: str,
        tools: List[AgenticTool] = None,
        max_iterations: int = 10,
        initial_context: Dict[str, Any] = None,
        stop_condition: Callable[[AgenticContext], bool] = None
    ) -> LoopResult:
        """
        Run the agentic loop to achieve a goal.

        Args:
            goal: The goal to achieve
            tools: Available tools
            max_iterations: Maximum loop iterations
            initial_context: Initial context/variables
            stop_condition: Custom stop condition function

        Returns:
            LoopResult with the outcome
        """
        import time
        start_time = time.time()

        self._running = True
        self._stop_requested = False

        # Initialize context
        context = AgenticContext(
            goal=goal,
            original_goal=goal,
            variables=initial_context or {}
        )

        tools = tools or []
        tools_map = {t.name: t for t in tools}

        # Initial observation
        initial_obs = Observation(
            source="system",
            content=f"Starting to work on goal: {goal}",
            observation_type="input"
        )
        context.add_observation(initial_obs)

        if self.verbose:
            logger.info(f"AgenticLoop started with goal: {goal}")

        iteration = 0
        final_answer = None
        achieved = False
        error = None

        try:
            while iteration < max_iterations and not self._stop_requested:
                iteration += 1

                if self.verbose:
                    logger.info(f"--- Iteration {iteration} ---")

                # Check for repetitive behavior and nudge toward completion
                if iteration >= 5:
                    tool_uses = sum(1 for s in context.steps if s.action and s.action.action_type == ActionType.USE_TOOL)
                    if tool_uses >= 4:
                        # Add hint to context that we should complete
                        context.set_artifact("completion_hint", 
                            f"You have used {tool_uses} tools over {iteration} iterations. "
                            "You likely have enough information. Consider completing with a comprehensive answer.")

                # THINK: Reason about what to do
                thought = await self._think(context, tools)

                if self.verbose:
                    logger.info(f"Thought: {thought.reasoning[:100]}...")
                    logger.info(f"Action: {thought.next_action.value}")

                # Check if goal completed
                if thought.next_action == ActionType.COMPLETE:
                    final_answer = thought.action_input.get("final_answer", "")
                    
                    # If no final_answer provided, synthesize from observations
                    if not final_answer:
                        final_answer = self._synthesize_answer(context, goal)
                    
                    achieved = True

                    # Create final step
                    action = Action(
                        action_type=ActionType.COMPLETE,
                        success=True,
                        result=final_answer
                    )
                    observation = Observation(
                        source="agent",
                        content=final_answer,
                        observation_type="result"
                    )
                    context.add_step(Step(
                        step_number=iteration,
                        thought=thought,
                        action=action,
                        observation=observation
                    ))
                    context.set_artifact("final_answer", final_answer)
                    break

                # ACT: Execute the action
                action = await self._act(thought, tools_map)

                # OBSERVE: Get the result
                observation = Observation(
                    source=action.tool_name or "agent",
                    content=action.result if action.success else action.error,
                    observation_type="result" if action.success else "error"
                )
                context.add_observation(observation)

                # REFLECT: Evaluate the action
                reflection = None
                if self.enable_reflection:
                    reflection = await self._reflect(thought, action, observation, context)

                    if self.verbose:
                        logger.info(f"Reflection: {reflection.lesson_learned}")

                # Record the step
                step = Step(
                    step_number=iteration,
                    thought=thought,
                    action=action,
                    observation=observation,
                    reflection=reflection
                )
                context.add_step(step)

                # Check custom stop condition
                if stop_condition and stop_condition(context):
                    if self.verbose:
                        logger.info("Custom stop condition met")
                    break

                # Handle reflection-driven retry
                if reflection and reflection.should_retry and reflection.retry_strategy:
                    context.variables["retry_hint"] = reflection.retry_strategy

        except Exception as e:
            logger.error(f"AgenticLoop error: {e}")
            error = str(e)

        finally:
            self._running = False

        # Determine status
        if self._stop_requested:
            status = LoopStatus.STOPPED
        elif error:
            status = LoopStatus.FAILED
        elif achieved:
            status = LoopStatus.COMPLETED
        elif iteration >= max_iterations:
            status = LoopStatus.MAX_ITERATIONS
            # Try to get partial answer
            if context.artifacts:
                final_answer = context.artifacts.get("final_answer",
                    "Goal not fully achieved within iteration limit")
        else:
            status = LoopStatus.COMPLETED

        total_time = time.time() - start_time

        return LoopResult(
            status=status,
            goal=goal,
            achieved=achieved,
            final_answer=final_answer,
            artifacts=context.artifacts,
            steps_taken=iteration,
            total_time=total_time,
            reasoning_trace=[s.to_dict() for s in context.steps],
            error=error
        )

    async def _think(
        self,
        context: AgenticContext,
        tools: List[AgenticTool]
    ) -> Thought:
        """
        Generate a thought using the LLM.

        This is where the agent reasons about what to do next.
        """
        from ..llm.providers import Message, MessageRole, LLMConfig

        # Build the prompt
        tools_description = self._format_tools(tools)
        context_str = context.to_prompt_context()

        # Include recent observations
        recent_obs = "\n".join([
            obs.to_prompt_string()
            for obs in context.get_recent_observations(5)
        ])

        completion_hint = context.artifacts.get("completion_hint", "")
        hint_text = f"\n\n⚠️ IMPORTANT: {completion_hint}" if completion_hint else ""

        user_prompt = f"""
{context_str}

AVAILABLE TOOLS:
{tools_description}

RECENT OBSERVATIONS:
{recent_obs}
{hint_text}

Based on the above, decide your next action. Remember to respond with valid JSON.
"""

        messages = [
            Message(MessageRole.SYSTEM, self.system_prompt),
            Message(MessageRole.USER, user_prompt)
        ]

        # Add retry hint if present
        if context.variables.get("retry_hint"):
            messages.append(Message(
                MessageRole.SYSTEM,
                f"HINT: Previous attempt suggested: {context.variables.pop('retry_hint')}"
            ))

        config = LLMConfig(temperature=0.7, max_tokens=2048)
        response = await self.llm.chat(messages, config)

        # Parse the response
        return self._parse_thought(response.content)

    def _parse_thought(self, llm_response: str) -> Thought:
        """Parse LLM response into a Thought object."""
        try:
            # Try to extract JSON from response
            import re

            # Look for JSON block
            json_match = re.search(r'\{[\s\S]*\}', llm_response)
            if json_match:
                data = json.loads(json_match.group())
            else:
                # Fallback: treat as reasoning with completion
                return Thought(
                    reasoning=llm_response,
                    next_action=ActionType.COMPLETE,
                    action_input={"final_answer": llm_response},
                    confidence=0.5
                )

            # Map action string to ActionType
            action_str = data.get("next_action", "complete").lower()
            action_map = {
                "use_tool": ActionType.USE_TOOL,
                "respond": ActionType.COMPLETE,  # Treat "respond" as "complete" to terminate loop
                "complete": ActionType.COMPLETE,
                "ask_user": ActionType.ASK_USER,
                "delegate": ActionType.DELEGATE,
                "wait": ActionType.WAIT
            }
            next_action = action_map.get(action_str, ActionType.COMPLETE)

            return Thought(
                reasoning=data.get("reasoning", ""),
                next_action=next_action,
                action_input=data.get("action_input", {}),
                confidence=float(data.get("confidence", 0.5)),
                goal_progress=float(data.get("goal_progress", 0.0)),
                should_continue=next_action != ActionType.COMPLETE
            )

        except json.JSONDecodeError:
            # If JSON parsing fails, treat as completion with the response
            return Thought(
                reasoning=llm_response,
                next_action=ActionType.COMPLETE,
                action_input={"final_answer": llm_response},
                confidence=0.5
            )

    async def _act(
        self,
        thought: Thought,
        tools_map: Dict[str, AgenticTool]
    ) -> Action:
        """
        Execute an action based on the thought.
        """
        import time
        start_time = time.time()

        action = Action(action_type=thought.next_action)

        try:
            if thought.next_action == ActionType.USE_TOOL:
                tool_name = thought.action_input.get("tool_name")
                parameters = thought.action_input.get("parameters", {})
                
                # Handle case where LLM puts parameters directly in action_input
                if not parameters and tool_name:
                    # Extract any other keys as parameters
                    parameters = {k: v for k, v in thought.action_input.items() 
                                  if k not in ["tool_name", "parameters"]}
                
                # Handle case where parameter is passed as single value
                if not parameters and "query" not in parameters:
                    # Check if there's an 'input' field
                    if "input" in thought.action_input:
                        parameters = {"query": thought.action_input["input"]}
                    elif "expression" in thought.action_input:
                        parameters = {"expression": thought.action_input["expression"]}

                if tool_name not in tools_map:
                    action.error = f"Tool not found: {tool_name}"
                    action.success = False
                else:
                    tool = tools_map[tool_name]
                    action.tool_name = tool_name
                    action.parameters = parameters

                    result = await tool.execute(**parameters)
                    action.result = result
                    action.success = True

            elif thought.next_action == ActionType.RESPOND:
                action.result = thought.action_input.get("response", "")
                action.success = True

            elif thought.next_action == ActionType.COMPLETE:
                action.result = thought.action_input.get("final_answer")
                action.success = True

            else:
                action.result = thought.action_input
                action.success = True

        except Exception as e:
            action.error = str(e)
            action.success = False
            logger.error(f"Action execution error: {e}")

        action.execution_time = time.time() - start_time
        return action

    async def _reflect(
        self,
        thought: Thought,
        action: Action,
        observation: Observation,
        context: AgenticContext
    ) -> Reflection:
        """
        Reflect on the action and its outcome.

        This enables self-correction by evaluating whether the
        action moved toward the goal and what can be learned.
        """
        from ..llm.providers import Message, MessageRole, LLMConfig

        reflection_prompt = f"""
Reflect on this action and its outcome:

GOAL: {context.goal}

THOUGHT: {thought.reasoning}

ACTION: {action.action_type.value}
{f"Tool: {action.tool_name}" if action.tool_name else ""}

RESULT: {"Success" if action.success else "Failed"}
{observation.content}

Evaluate:
1. Did the action succeed technically?
2. Did it make progress toward the goal?
3. What lesson can be learned?
4. Should we retry with a different approach?

Respond with JSON:
{{
    "action_succeeded": true/false,
    "goal_progress_made": true/false,
    "lesson_learned": "what we learned from this step",
    "should_retry": true/false,
    "retry_strategy": "what to try differently (if retrying)"
}}
"""

        messages = [
            Message(MessageRole.SYSTEM, "You are a reflective AI that evaluates actions and learns from outcomes."),
            Message(MessageRole.USER, reflection_prompt)
        ]

        config = LLMConfig(temperature=0.3, max_tokens=512)
        response = await self.llm.chat(messages, config)

        return self._parse_reflection(response.content, action.success)

    def _parse_reflection(self, llm_response: str, action_success: bool) -> Reflection:
        """Parse LLM response into a Reflection object."""
        try:
            import re
            json_match = re.search(r'\{[\s\S]*\}', llm_response)
            if json_match:
                data = json.loads(json_match.group())
                return Reflection(
                    action_succeeded=data.get("action_succeeded", action_success),
                    goal_progress_made=data.get("goal_progress_made", action_success),
                    lesson_learned=data.get("lesson_learned", ""),
                    should_retry=data.get("should_retry", False),
                    retry_strategy=data.get("retry_strategy")
                )
        except (json.JSONDecodeError, AttributeError):
            pass

        # Fallback
        return Reflection(
            action_succeeded=action_success,
            goal_progress_made=action_success,
            lesson_learned="Completed step",
            should_retry=False
        )

    def _synthesize_answer(self, context: AgenticContext, goal: str) -> str:
        """
        Synthesize a final answer from the observations collected during the loop.
        
        This is used when the LLM completes without providing a final_answer.
        """
        # Collect all observations from tool results
        observations = []
        for step in context.steps:
            if step.observation and step.observation.content:
                content = str(step.observation.content)
                if content and not content.startswith("Error"):
                    observations.append(content)
        
        if not observations:
            return f"Unable to fully answer: {goal}"
        
        # Combine observations into a coherent answer
        combined = "\n".join(observations)
        
        # Create a summary
        answer = f"Based on my research:\n\n{combined}"
        
        return answer

    def _format_tools(self, tools: List[AgenticTool]) -> str:
        """Format tools for the prompt."""
        if not tools:
            return "No tools available."

        lines = []
        for tool in tools:
            params = ", ".join([
                f"{name}: {info.get('type', 'string')}"
                for name, info in tool.parameters.items()
            ])
            lines.append(f"- {tool.name}({params}): {tool.description}")

        return "\n".join(lines)

    def stop(self):
        """Request the loop to stop after current iteration."""
        self._stop_requested = True

    @property
    def is_running(self) -> bool:
        return self._running


# ============================================================================
# CONVENIENCE FUNCTIONS
# ============================================================================

async def run_agentic_task(
    goal: str,
    llm_provider,
    tools: List[AgenticTool] = None,
    max_iterations: int = 10,
    verbose: bool = False
) -> LoopResult:
    """
    Convenience function to run a single agentic task.

    Usage:
        result = await run_agentic_task(
            goal="Summarize the main points of Python 3.12",
            llm_provider=OllamaProvider(model="llama3.1"),
            tools=[search_tool],
            max_iterations=5
        )
    """
    loop = AgenticLoop(llm_provider=llm_provider, verbose=verbose)
    return await loop.run(goal=goal, tools=tools, max_iterations=max_iterations)


def create_tool(
    name: str,
    description: str,
    function: Callable,
    parameters: Dict[str, Dict[str, str]] = None
) -> AgenticTool:
    """
    Convenience function to create a tool.

    Usage:
        search_tool = create_tool(
            name="web_search",
            description="Search the web for information",
            function=search_function,
            parameters={
                "query": {"type": "string", "description": "Search query", "required": True}
            }
        )
    """
    return AgenticTool(
        name=name,
        description=description,
        function=function,
        parameters=parameters or {}
    )
